---
title: Minimax Excess Risk of First-Order Methods for Statistical Learning with Data-Dependent
  Oracles
abstract: In this paper, our aim is to analyse the generalization capabilities of
  first-order methods for statistical learning in multiple, different yet related,
  scenarios including supervised learning, transfer learning, robust learning and
  federated learning. To do so, we provide sharp upper and lower bounds for the minimax
  excess risk of strongly convex and smooth statistical learning when the gradient
  is accessed through partial observations given by a data-dependent oracle. This
  novel class of oracles can query the gradient with any given data distribution,
  and is thus well suited to scenarios in which the training data distribution does
  not match the target (or test) distribution. In particular, our upper and lower
  bounds are proportional to the smallest mean square error achievable by gradient
  estimators, thus allowing us to easily derive multiple sharp bounds in the aforementioned
  scenarios using the extensive literature on parameter estimation.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: scaman24a
month: 0
tex_title: Minimax Excess Risk of First-Order Methods for Statistical Learning with
  Data-Dependent Oracles
firstpage: 3709
lastpage: 3717
page: 3709-3717
order: 3709
cycles: false
bibtex_author: Scaman, Kevin and Even, Mathieu and Le Bars, Batiste and Massoulie,
  Laurent
author:
- given: Kevin
  family: Scaman
- given: Mathieu
  family: Even
- given: Batiste
  family: Le Bars
- given: Laurent
  family: Massoulie
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/scaman24a/scaman24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
