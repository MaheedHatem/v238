---
title: Pathwise Explanation of ReLU Neural Networks
software: https://github.com/Jo-won/PathwiseExplanation
abstract: Neural networks have demonstrated a wide range of successes, but their â€œblack
  box" nature raises concerns about transparency and reliability. Previous research
  on ReLU networks has sought to unwrap these networks into linear models based on
  activation states of all hidden units. In this paper, we introduce a novel approach
  that considers subsets of the hidden units involved in the decision making path.
  This pathwise explanation provides a clearer and more consistent understanding of
  the relationship between the input and the decision-making process. Our method also
  offers flexibility in adjusting the range of explanations within the input, i.e.,
  from an overall attribution input to particular components within the input. Furthermore,
  it allows for the decomposition of explanations for a given input for more detailed
  explanations. Our experiments demonstrate that the proposed method outperforms existing
  methods both quantitatively and qualitatively.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lim24a
month: 0
tex_title: Pathwise Explanation of {ReLU} Neural Networks
firstpage: 4645
lastpage: 4653
page: 4645-4653
order: 4645
cycles: false
bibtex_author: Lim, Seongwoo and Jo, Won and Lee, Joohyung and Choi, Jaesik
author:
- given: Seongwoo
  family: Lim
- given: Won
  family: Jo
- given: Joohyung
  family: Lee
- given: Jaesik
  family: Choi
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/lim24a/lim24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
