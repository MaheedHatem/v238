---
title: 'Krylov Cubic Regularized Newton: A Subspace Second-Order Method with Dimension-Free
  Convergence Rate'
software: https://github.com/Raymond30/Krylov-Cubic-Regularized-Newton
abstract: Second-order optimization methods, such as cubic regularized Newton methods,
  are known for their rapid convergence rates; nevertheless, they become impractical
  in high-dimensional problems due to their substantial memory requirements and computational
  costs. One promising approach is to execute second-order updates within a lower-dimensional
  subspace, giving rise to subspace second-order methods. However, the majority of
  existing subspace second-order methods randomly select subspaces, consequently resulting
  in slower convergence rates depending on the problemâ€™s dimension $d$. In this paper,
  we introduce a novel subspace cubic regularized Newton method that achieves a dimension-independent
  global convergence rate of $\mathcal{O}\left(\frac{1}{mk}+\frac{1}{k^2}\right)$
  for solving convex optimization problems. Here, $m$ represents the subspace dimension,
  which can be significantly smaller than $d$. Instead of adopting a random subspace,
  our primary innovation involves performing the cubic regularized Newton update within
  the \emph{Krylov subspace} associated with the Hessian and the gradient of the objective
  function. This result marks the first instance of a dimension-independent convergence
  rate for a subspace second-order method. Furthermore, when specific spectral conditions
  of the Hessian are met, our method recovers the convergence rate of a full-dimensional
  cubic regularized Newton method. Numerical experiments show our method converges
  faster than existing random subspace methods, especially for high-dimensional problems.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jiang24a
month: 0
tex_title: 'Krylov Cubic Regularized {N}ewton: A Subspace Second-Order Method with
  Dimension-Free Convergence Rate'
firstpage: 4411
lastpage: 4419
page: 4411-4419
order: 4411
cycles: false
bibtex_author: Jiang, Ruichen and Raman, Parameswaran and Sabach, Shoham and Mokhtari,
  Aryan and Hong, Mingyi and Cevher, Volkan
author:
- given: Ruichen
  family: Jiang
- given: Parameswaran
  family: Raman
- given: Shoham
  family: Sabach
- given: Aryan
  family: Mokhtari
- given: Mingyi
  family: Hong
- given: Volkan
  family: Cevher
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/jiang24a/jiang24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
