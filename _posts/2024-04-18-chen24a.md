---
title: Lower-level Duality Based Reformulation and Majorization Minimization Algorithm
  for Hyperparameter Optimization
software: https://github.com/libra-licoho/LDMMA
abstract: Hyperparameter tuning is an important task of machine learning, which can
  be formulated as a bilevel program (BLP). However, most existing algorithms are
  not applicable for BLP with non-smooth lower-level problems. To address this, we
  propose a single-level reformulation of the BLP based on lower-level duality without
  involving any implicit value function. To solve the reformulation, we propose a
  majorization minimization algorithm that marjorizes the constraint in each iteration.
  Furthermore, we show that the subproblems of the proposed algorithm for several
  widely-used hyperparameter turning models can be reformulated into conic programs
  that can be efficiently solved by the off-the-shelf solvers. We theoretically prove
  the convergence of the proposed algorithm and demonstrate its superiority through
  numerical experiments.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen24a
month: 0
tex_title: Lower-level Duality Based Reformulation and Majorization Minimization Algorithm
  for Hyperparameter Optimization
firstpage: 784
lastpage: 792
page: 784-792
order: 784
cycles: false
bibtex_author: Chen, He and Xu, Haochen and Jiang, Rujun and Man-Cho So, Anthony
author:
- given: He
  family: Chen
- given: Haochen
  family: Xu
- given: Rujun
  family: Jiang
- given: Anthony
  family: Man-Cho So
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/chen24a/chen24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
