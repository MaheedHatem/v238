---
title: Multi-Dimensional Hyena for Spatial Inductive Bias
software: https://github.com/Itamarzimm/HyenaND
abstract: The advantage of Vision Transformers over CNNs is only fully manifested
  when trained over a large dataset, mainly due to the reduced inductive bias towards
  spatial locality within the transformerâ€™s self-attention mechanism. In this work,
  we present a data-efficient vision transformer that does not rely on self-attention.
  Instead, it employs a novel generalization to multiple axes of the very recent Hyena
  layer. We propose several alternative approaches for obtaining this generalization
  and delve into their unique distinctions and considerations from both empirical
  and theoretical perspectives. The proposed Hyena N-D layer boosts the performance
  of various Vision Transformer architectures, such as ViT, Swin, and DeiT across
  multiple datasets. Furthermore, in the small dataset regime, our Hyena-based ViT
  is favorable to ViT variants from the recent literature that are specifically designed
  for solving the same challenge. Finally, we show that a hybrid approach that is
  based on Hyena N-D for the first layers in ViT, followed by layers that incorporate
  conventional attention, consistently boosts the performance of various vision transformer
  architectures. Our code is attached as supplementary.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zimerman24a
month: 0
tex_title: Multi-Dimensional {H}yena for Spatial Inductive Bias
firstpage: 973
lastpage: 981
page: 973-981
order: 973
cycles: false
bibtex_author: Zimerman, Itamar and Wolf, Lior
author:
- given: Itamar
  family: Zimerman
- given: Lior
  family: Wolf
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/zimerman24a/zimerman24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
