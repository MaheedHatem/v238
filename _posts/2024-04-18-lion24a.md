---
title: How Good is a Single Basin?
abstract: The multi-modal nature of neural loss landscapes is often considered to
  be the main driver behind the empirical success of deep ensembles. In this work,
  we probe this belief by constructing various "connected" ensembles which are restricted
  to lie in the same basin. Through our experiments, we demonstrate that increased
  connectivity indeed negatively impacts performance. However, when incorporating
  the knowledge from other basins implicitly through distillation, we show that the
  gap in performance can be mitigated by re-discovering (multi-basin) deep ensembles
  within a single basin. Thus, we conjecture that while the extra-basin knowledge
  is at least partially present in any given basin, it cannot be easily harnessed
  without learning it from other basins.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lion24a
month: 0
tex_title: How Good is a Single Basin?
firstpage: 4015
lastpage: 4023
page: 4015-4023
order: 4015
cycles: false
bibtex_author: Lion, Kai and Noci, Lorenzo and Hofmann, Thomas and Bachmann, Gregor
author:
- given: Kai
  family: Lion
- given: Lorenzo
  family: Noci
- given: Thomas
  family: Hofmann
- given: Gregor
  family: Bachmann
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/lion24a/lion24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
