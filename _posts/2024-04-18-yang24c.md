---
title: Identifying Spurious Biases Early in Training through the Lens of Simplicity
  Bias
software: https://github.com/BigML-CS-UCLA/SPARE
abstract: Neural networks trained with (stochastic) gradient descent have an inductive
  bias towards learning simpler solutions. This makes them highly prone to learning
  spurious correlations in the training data, that may not hold at test time. In this
  work, we provide the first theoretical analysis of the effect of simplicity bias
  on learning spurious correlations. Notably, we show that examples with spurious
  features are provably separable based on the model’s output early in training. We
  further illustrate that if spurious features have a small enough noise-to-signal
  ratio, the network’s output on majority of examples is almost exclusively determined
  by the spurious features, leading to poor worst-group test accuracy. Finally, we
  propose SPARE, which identifies spurious correlations early in training, and utilizes
  importance sampling to alleviate their effect. Empirically, we demonstrate that
  SPARE outperforms state-of-the-art methods by up to 21.1% in worst-group accuracy,
  while being up to 12x faster. We also show the applicability of SPARE, as a highly
  effective but lightweight method, to discover spurious correlations.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yang24c
month: 0
tex_title: Identifying Spurious Biases Early in Training through the Lens of Simplicity
  Bias
firstpage: 2953
lastpage: 2961
page: 2953-2961
order: 2953
cycles: false
bibtex_author: Yang, Yu and Gan, Eric and Karolina Dziugaite, Gintare and Mirzasoleiman,
  Baharan
author:
- given: Yu
  family: Yang
- given: Eric
  family: Gan
- given: Gintare
  family: Karolina Dziugaite
- given: Baharan
  family: Mirzasoleiman
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/yang24c/yang24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
