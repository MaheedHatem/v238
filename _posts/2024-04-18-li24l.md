---
title: 'Policy Evaluation for Reinforcement Learning from Human Feedback: A Sample
  Complexity Analysis'
abstract: A recently popular approach to solving reinforcement learning is with data
  from human preferences. In fact, human preference data are now used with classic
  reinforcement learning algorithms such as actor-critic methods, which involve evaluating
  an intermediate policy over a reward learned from human preference data with distribution
  shift, known as off-policy evaluation (OPE). Such algorithm includes (i) learning
  reward function from human preference dataset, and (ii) learning expected cumulative
  reward of a target policy. Despite the huge empirical success, existing OPE methods
  with preference data often lack theoretical understandings and rely heavily on heuristics.
  In this paper, we study the sample efficiency of OPE with human preference and establish
  a statistical guarantee for it. Specifically, we approach OPE with learning the
  value function by fitted-Q-evaluation with a deep neural network. By appropriately
  selecting the size of a ReLU network, we show that one can leverage any low-dimensional
  manifold structure in the Markov decision process and obtain a sample-efficient
  estimator without suffering from the curse of high data ambient dimensionality.
  Under the assumption of high reward smoothness, our results almost align with the
  classical OPE results with observable reward data. To the best of our knowledge,
  this is the first result that establishes a provably efficient guarantee for off-policy
  evaluation with RLHF.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li24l
month: 0
tex_title: 'Policy Evaluation for Reinforcement Learning from Human Feedback: A Sample
  Complexity Analysis'
firstpage: 2737
lastpage: 2745
page: 2737-2745
order: 2737
cycles: false
bibtex_author: Li, Zihao and Ji, Xiang and Chen, Minshuo and Wang, Mengdi
author:
- given: Zihao
  family: Li
- given: Xiang
  family: Ji
- given: Minshuo
  family: Chen
- given: Mengdi
  family: Wang
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/li24l/li24l.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
