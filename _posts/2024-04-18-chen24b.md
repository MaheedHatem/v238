---
title: An Efficient Stochastic Algorithm for Decentralized Nonconvex-Strongly-Concave
  Minimax Optimization
software: https://github.com/TrueNobility303/DREAM
abstract: This paper studies the stochastic nonconvex-strongly-concave minimax optimization
  over a multi-agent network. We propose an efficient algorithm, called Decentralized
  Recursive gradient descEnt Ascent Method (DREAM), which achieves the best-known
  theoretical guarantee for finding the $\epsilon$-stationary points. Concretely,
  it requires $\mathcal{O}(\min (\kappa^3\epsilon^{-3},\kappa^2 \sqrt{N} \epsilon^{-2}
  ))$ stochastic first-order oracle (SFO) calls and $\tilde \mathcal O(\kappa^2 \epsilon^{-2})$
  communication rounds, where $\kappa$ is the condition number and $N$ is the total
  number of individual functions. Our numerical experiments also validate the superiority
  of DREAM over previous methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen24b
month: 0
tex_title: An Efficient Stochastic Algorithm for Decentralized Nonconvex-Strongly-Concave
  Minimax Optimization
firstpage: 1990
lastpage: 1998
page: 1990-1998
order: 1990
cycles: false
bibtex_author: Chen, Lesi and Ye, Haishan and Luo, Luo
author:
- given: Lesi
  family: Chen
- given: Haishan
  family: Ye
- given: Luo
  family: Luo
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/chen24b/chen24b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
