---
title: 'FairRR: Pre-Processing for Group Fairness through Randomized Response'
software: https://github.com/UCLA-Trustworthy-AI-Lab/FairRR
abstract: The increasing usage of machine learning models in consequential decision-making
  processes has spurred research into the fairness of these systems. While significant
  work has been done to study group fairness in the in-processing and post-processing
  setting, there has been little that theoretically connects these results to the
  pre-processing domain. This paper extends recent fair statistical learning results
  and proposes that achieving group fairness in downstream models can be formulated
  as finding the optimal design matrix in which to modify a response variable in a
  Randomized Response framework. We show that measures of group fairness can be directly
  controlled for with optimal model utility, proposing a pre-processing algorithm
  called FairRR that yields excellent downstream model utility and fairness.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: john-ward24a
month: 0
tex_title: "{F}air{RR}: Pre-Processing for Group Fairness through Randomized Response"
firstpage: 3826
lastpage: 3834
page: 3826-3834
order: 3826
cycles: false
bibtex_author: John Ward, Joshua and Zeng, Xianli and Cheng, Guang
author:
- given: Joshua
  family: John Ward
- given: Xianli
  family: Zeng
- given: Guang
  family: Cheng
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/john-ward24a/john-ward24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
