---
title: Taming Nonconvex Stochastic Mirror Descent with General Bregman Divergence
abstract: This paper revisits the convergence of Stochastic Mirror Descent (SMD) in
  the contemporary nonconvex optimization setting. Existing results for batch-free
  nonconvex SMD restrict the choice of the distance generating function (DGF) to be
  differentiable with Lipschitz continuous gradients, thereby excluding important
  setups such as Shannon entropy. In this work, we present a new convergence analysis
  of nonconvex SMD supporting general DGF, that overcomes the above limitations and
  relies solely on the standard assumptions. Moreover, our convergence is established
  with respect to the Bregman Forward-Backward envelope, which is a stronger measure
  than the commonly used squared norm of gradient mapping. We further extend our results
  to guarantee high probability convergence under sub-Gaussian noise and global convergence
  under the generalized Bregman Proximal Polyak-{≈Å}ojasiewicz condition. Additionally,
  we illustrate the advantages of our improved SMD theory in various nonconvex machine
  learning tasks by harnessing nonsmooth DGFs. Notably, in the context of nonconvex
  differentially private (DP) learning, our theory yields a simple algorithm with
  a (nearly) dimension-independent utility bound. For the problem of training linear
  neural networks, we develop provably convergent stochastic algorithms.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: fatkhullin24a
month: 0
tex_title: Taming Nonconvex Stochastic Mirror Descent with General {B}regman Divergence
firstpage: 3493
lastpage: 3501
page: 3493-3501
order: 3493
cycles: false
bibtex_author: Fatkhullin, Ilyas and He, Niao
author:
- given: Ilyas
  family: Fatkhullin
- given: Niao
  family: He
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/fatkhullin24a/fatkhullin24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
