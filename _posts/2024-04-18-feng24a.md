---
title: Is this model reliable for everyone? Testing for strong calibration
software: https://github.com/jjfeng/testing_strong_calibration
abstract: 'In a well-calibrated risk prediction model, the average predicted probability
  is close to the true event rate for any given subgroup. Such models are reliable
  across heterogeneous populations and satisfy strong notions of algorithmic fairness.
  However, the task of auditing a model for strong calibration is well-known to be
  difficult—particularly for machine learning (ML) algorithms—due to the sheer number
  of potential subgroups. As such, common practice is to only assess calibration with
  respect to a few predefined subgroups. Recent developments in goodness-of-fit testing
  offer potential solutions but are not designed for settings with weak signal or
  where the poorly calibrated subgroup is small, as they either overly subdivide the
  data or fail to divide the data at all. We introduce a new testing procedure based
  on the following insight: if we can reorder observations by their expected residuals,
  there should be a change in the association between the predicted and observed residuals
  along this sequence if a poorly calibrated subgroup exists. This lets us reframe
  the problem of calibration testing into one of changepoint detection, for which
  powerful methods already exist. We begin with introducing a sample-splitting procedure
  where a portion of the data is used to train a suite of candidate models for predicting
  the residual, and the remaining data are used to perform a score-based cumulative
  sum (CUSUM) test. To further improve power, we then extend this adaptive CUSUM test
  to incorporate cross-validation, while maintaining Type I error control under minimal
  assumptions. Compared to existing methods, the proposed procedure consistently achieved
  higher power in empirical analyses.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: feng24a
month: 0
tex_title: Is this model reliable for everyone? Testing for strong calibration
firstpage: 181
lastpage: 189
page: 181-189
order: 181
cycles: false
bibtex_author: Feng, Jean and Gossmann, Alexej and Pirracchio, Romain and Petrick,
  Nicholas and A Pennello, Gene and Sahiner, Berkman
author:
- given: Jean
  family: Feng
- given: Alexej
  family: Gossmann
- given: Romain
  family: Pirracchio
- given: Nicholas
  family: Petrick
- given: Gene
  family: A Pennello
- given: Berkman
  family: Sahiner
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/feng24a/feng24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
