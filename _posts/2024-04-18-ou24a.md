---
title: Thompson Sampling Itself is Differentially Private
abstract: In this work we first show that the classical Thompson sampling algorithm
  for multi-arm bandits is differentially private as-is, without any modification.
  We provide per-round privacy guarantees as a function of problem parameters and
  show composition over $T$ rounds; since the algorithm is unchanged, existing $O(\sqrt{NT\log
  N})$ regret bounds still hold and there is no loss in performance due to privacy.
  We then show that simple modifications – such as pre-pulling all arms a fixed number
  of times, increasing the sampling variance – can provide tighter privacy guarantees.
  We again provide privacy guarantees that now depend on the new parameters introduced
  in the modification, which allows the analyst to tune the privacy guarantee as desired.
  We also provide a novel regret analysis for this new algorithm, and show how the
  new parameters also impact expected regret. Finally, we empirically validate and
  illustrate our theoretical findings in two parameter regimes and demonstrate that
  tuning the new parameters substantially improve the privacy-regret tradeoff.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ou24a
month: 0
tex_title: Thompson Sampling Itself is Differentially Private
firstpage: 1576
lastpage: 1584
page: 1576-1584
order: 1576
cycles: false
bibtex_author: Ou, Tingting and Cummings, Rachel and Avella Medina, Marco
author:
- given: Tingting
  family: Ou
- given: Rachel
  family: Cummings
- given: Marco
  family: Avella Medina
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/ou24a/ou24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
