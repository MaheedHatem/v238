---
title: Certified private data release for sparse Lipschitz functions
abstract: As machine learning has become more relevant for everyday applications,
  a natural requirement is the protection of the privacy of the training data. When
  the relevant learning questions are unknown in advance, or hyper-parameter tuning
  plays a central role, one solution is to release a differentially private synthetic
  data set that leads to similar conclusions as the original training data. In this
  work, we introduce an algorithm that enjoys fast rates for the utility loss for
  sparse Lipschitz queries. Furthermore, we show how to obtain a certificate for the
  utility loss for a large class of algorithms.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: donhauser24a
month: 0
tex_title: Certified private data release for sparse {L}ipschitz functions
firstpage: 1396
lastpage: 1404
page: 1396-1404
order: 1396
cycles: false
bibtex_author: Donhauser, Konstantin and Lokna, Johan and Sanyal, Amartya and Boedihardjo,
  March and H\"{o}nig, Robert and Yang, Fanny
author:
- given: Konstantin
  family: Donhauser
- given: Johan
  family: Lokna
- given: Amartya
  family: Sanyal
- given: March
  family: Boedihardjo
- given: Robert
  family: HÃ¶nig
- given: Fanny
  family: Yang
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/donhauser24a/donhauser24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
