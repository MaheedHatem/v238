---
title: Near Optimal Adversarial Attacks on Stochastic Bandits and Defenses with Smoothed
  Responses
software: https://github.com/ShiliangZuo/BanditAttack.git
abstract: I study adversarial attacks against stochastic bandit algorithms. At each
  round, the learner chooses an arm, and a stochastic reward is generated. The adversary
  strategically adds corruption to the reward, and the learner is only able to observe
  the corrupted reward at each round. Two sets of results are presented in this paper.
  The first set studies the optimal attack strategies for the adversary. The adversary
  has a target arm he wishes to promote, and his goal is to manipulate the learner
  into choosing this target arm $T - o(T)$ times. I design attack strategies against
  UCB and Thompson Sampling that only spends $\widehat{O}(\sqrt{\log T})$ cost. Matching
  lower bounds are presented, and the vulnerability of UCB, Thompson sampling and
  $\varepsilon$-greedy are exactly characterized. The second set studies how the learner
  can defend against the adversary. Inspired by literature on smoothed analysis and
  behavioral economics, I present two simple algorithms that achieve a competitive
  ratio arbitrarily close to 1.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zuo24a
month: 0
tex_title: Near Optimal Adversarial Attacks on Stochastic Bandits and Defenses with
  Smoothed Responses
firstpage: 2098
lastpage: 2106
page: 2098-2106
order: 2098
cycles: false
bibtex_author: Zuo, Shiliang
author:
- given: Shiliang
  family: Zuo
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/zuo24a/zuo24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
