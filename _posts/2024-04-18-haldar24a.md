---
title: Effect of Ambient-Intrinsic Dimension Gap on Adversarial Vulnerability
abstract: 'The existence of adversarial attacks on machine learning models imperceptible
  to a human is still quite a mystery from a theoretical perspective. In this work,
  we introduce two notions of adversarial attacks: natural or on-manifold attacks,
  which are perceptible by a human/oracle, and unnatural or off-manifold attacks,
  which are not. We argue that the existence of the off-manifold attacks is a natural
  consequence of the dimension gap between the intrinsic and ambient dimensions of
  the data. For 2-layer ReLU networks, we prove that even though the dimension gap
  does not affect generalization performance on samples drawn from the observed data
  space, it makes the clean-trained model more vulnerable to adversarial perturbations
  in the off-manifold direction of the data space. Our main results provide an explicit
  relationship between the $\ell_2,\ell_{\infty}$ attack strength of the on/off-manifold
  attack and the dimension gap.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: haldar24a
month: 0
tex_title: Effect of Ambient-Intrinsic Dimension Gap on Adversarial Vulnerability
firstpage: 1090
lastpage: 1098
page: 1090-1098
order: 1090
cycles: false
bibtex_author: Haldar, Rajdeep and Xing, Yue and Song, Qifan
author:
- given: Rajdeep
  family: Haldar
- given: Yue
  family: Xing
- given: Qifan
  family: Song
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/haldar24a/haldar24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
