---
title: 'Implicit Bias in Noisy-SGD: With Applications to Differentially Private Training'
abstract: Training Deep Neural Networks (DNNs) with small batches using Stochastic
  Gradient Descent (SGD) often results in superior test performance compared to larger
  batches. This implicit bias is attributed to the specific noise structure inherent
  to SGD. When ensuring Differential Privacy (DP) in DNNsâ€™ training, DP-SGD adds Gaussian
  noise to the clipped gradients. However, large-batch training still leads to a significant
  performance decrease, posing a challenge as strong DP guarantees necessitate the
  use of massive batches. Our study first demonstrates that this phenomenon extends
  to Noisy-SGD (DP-SGD without clipping), suggesting that the stochasticity, not the
  clipping, is responsible for this implicit bias, even with additional isotropic
  Gaussian noise. We then theoretically analyze the solutions obtained with continuous
  versions of Noisy-SGD for the Linear Least Square and Diagonal Linear Network settings.
  Our analysis reveals that the additional noise indeed amplifies the implicit bias.
  It suggests that the performance issues of private training stem from the same underlying
  principles as SGD, offering hope for improvements in large batch training strategies.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sander24a
month: 0
tex_title: 'Implicit Bias in Noisy-{SGD}: With Applications to Differentially Private
  Training'
firstpage: 3295
lastpage: 3303
page: 3295-3303
order: 3295
cycles: false
bibtex_author: Sander, Tom and Sylvestre, Maxime and Durmus, Alain
author:
- given: Tom
  family: Sander
- given: Maxime
  family: Sylvestre
- given: Alain
  family: Durmus
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/sander24a/sander24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
