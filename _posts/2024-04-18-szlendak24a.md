---
title: Understanding Progressive Training Through the Framework of Randomized Coordinate
  Descent
software: https://github.com/gaseln/progressive-exps
abstract: We propose a Randomized Progressive Training algorithm (RPT)—a stochastic
  proxy for the well-known Progressive Training method (PT) (Karras et al., 2017).
  Originally designed to train GANs (Goodfellow et al., 2014), PT was proposed as
  a heuristic, with no convergence analysis even for the simplest objective functions.
  On the contrary, to the best of our knowledge, RPT is the first PT-type algorithm
  with rigorous and sound theoretical guarantees for general smooth objective functions.
  We cast our method into the established framework of Randomized Coordinate Descent
  (RCD) (Nesterov, 2012; Richtarik & Takac, 2014), for which (as a by-product of our
  investigations) we also propose a novel, simple and general convergence analysis
  encapsulating strongly-convex, convex and nonconvex objectives. We then use this
  framework to establish a convergence theory for RPT. Finally, we validate the effectiveness
  of our method through extensive computational experiments.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: szlendak24a
month: 0
tex_title: Understanding Progressive Training Through the Framework of Randomized
  Coordinate Descent
firstpage: 2161
lastpage: 2169
page: 2161-2169
order: 2161
cycles: false
bibtex_author: Szlendak, Rafa\l{} and Gasanov, Elnur and Richtarik, Peter
author:
- given: Rafał
  family: Szlendak
- given: Elnur
  family: Gasanov
- given: Peter
  family: Richtarik
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/szlendak24a/szlendak24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
