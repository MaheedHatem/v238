---
title: Understanding Inverse Scaling and Emergence in Multitask Representation Learning
abstract: Large language models exhibit strong multitasking capabilities, however,
  their learning dynamics as a function of task characteristics, sample size, and
  model complexity remain mysterious. For instance, it is known that, as the model
  size grows, large language models exhibit emerging abilities where certain tasks
  can abruptly jump from poor to respectable performance. Such phenomena motivate
  a deeper understanding of how individual tasks evolve during multitasking. To this
  aim, we study a multitask representation learning setup where tasks can have distinct
  distributions, quantified by their covariance priors. Through random matrix theory,
  we precisely characterize the optimal linear representation for few-shot learning
  that minimizes the average test risk in terms of task covariances. When tasks have
  equal sample sizes, we prove a reduction to an equivalent problem with a single
  effective covariance from which the individual task risks of the original problem
  can be deduced. Importantly, we introduce “task competition” to explain how tasks
  with dominant covariance eigenspectrum emerge faster than others. We show that task
  competition can potentially explain the inverse scaling of certain tasks i.e. reduced
  test accuracy as the model grows. Overall, this work sheds light on the risk and
  emergence of individual tasks and uncovers new high-dimensional phenomena (including
  multiple-descent risk curves) that arise in multitask representation learning.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ildiz24a
month: 0
tex_title: Understanding Inverse Scaling and Emergence in Multitask Representation
  Learning
firstpage: 4726
lastpage: 4734
page: 4726-4734
order: 4726
cycles: false
bibtex_author: Ildiz, Muhammed E. and Zhao, Zhe and Oymak, Samet
author:
- given: Muhammed E.
  family: Ildiz
- given: Zhe
  family: Zhao
- given: Samet
  family: Oymak
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/ildiz24a/ildiz24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
