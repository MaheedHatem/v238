---
title: On the Statistical Efficiency of Mean-Field Reinforcement Learning with General
  Function Approximation
abstract: In this paper, we study the fundamental statistical efficiency of Reinforcement
  Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general model-based
  function approximation. We introduce a new concept called Mean-Field Model-Based
  Eluder Dimension (MF-MBED), which characterizes the inherent complexity of mean-field
  model classes. We show that a rich family of Mean-Field RL problems exhibits low
  MF-MBED. Additionally, we propose algorithms based on maximal likelihood estimation,
  which can return an $\epsilon$-optimal policy for MFC or an $\epsilon$-Nash Equilibrium
  policy for MFG. The overall sample complexity depends only polynomially on MF-MBED,
  which is potentially much lower than the size of state-action space. Compared with
  previous works, our results only require the minimal assumptions including realizability
  and Lipschitz continuity.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: huang24a
month: 0
tex_title: On the Statistical Efficiency of Mean-Field Reinforcement Learning with
  General Function Approximation
firstpage: 289
lastpage: 297
page: 289-297
order: 289
cycles: false
bibtex_author: Huang, Jiawei and Yardim, Batuhan and He, Niao
author:
- given: Jiawei
  family: Huang
- given: Batuhan
  family: Yardim
- given: Niao
  family: He
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/huang24a/huang24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
