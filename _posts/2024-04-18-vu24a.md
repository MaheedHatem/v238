---
title: Analysis of Privacy Leakage in Federated Large Language Models
software: https://github.com/vunhatminh/FL_Attacks.git
abstract: With the rapid adoption of Federated Learning (FL) as the training and tuning
  protocol for applications utilizing Large Language Models (LLMs), recent research
  highlights the need for significant modifications to FL to accommodate the large-scale
  of LLMs. While substantial adjustments to the protocol have been introduced as a
  response, comprehensive privacy analysis for the adapted FL protocol is currently
  lacking. To address this gap, our work delves into an extensive examination of the
  privacy analysis of FL when used for training LLMs, both from theoretical and practical
  perspectives. In particular, we design two active membership inference attacks with
  guaranteed theoretical success rates to assess the privacy leakages of various adapted
  FL configurations. Our theoretical findings are translated into practical attacks,
  revealing substantial privacy vulnerabilities in popular LLMs, including BERT, RoBERTa,
  DistilBERT, and OpenAI’s GPTs, across multiple real-world language datasets. Additionally,
  we conduct thorough experiments to evaluate the privacy leakage of these models
  when data is protected by state-of-the-art differential privacy (DP) mechanisms.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: vu24a
month: 0
tex_title: Analysis of Privacy Leakage in Federated Large Language Models
firstpage: 1423
lastpage: 1431
page: 1423-1431
order: 1423
cycles: false
bibtex_author: Vu, Minh and Nguyen, Truc and Jeter, Tre' and T. Thai, My
author:
- given: Minh
  family: Vu
- given: Truc
  family: Nguyen
- given: Tre’
  family: Jeter
- given: My
  family: T. Thai
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/vu24a/vu24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
