---
title: Exploration via linearly perturbed loss minimisation
software: https://github.com/DavidJanz/EVILL-code
abstract: We introduce \emph{exploration via linear loss perturbations} (EVILL), a
  randomised exploration method for structured stochastic bandit problems that works
  by solving for the minimiser of a linearly perturbed regularised negative log-likelihood
  function. We show that, for the case of generalised linear bandits, EVILL reduces
  to perturbed history exploration (PHE), a method where exploration is done by training
  on randomly perturbed rewards. In doing so, we provide a simple and clean explanation
  of when and why random reward perturbations give rise to good bandit algorithms.
  We propose data-dependent perturbations not present in previous PHE-type methods
  that allow EVILL to match the performance of Thompson-sampling-style parameter-perturbation
  methods, both in theory and in practice. Moreover, we show an example outside generalised
  linear bandits where PHE leads to inconsistent estimates, and thus linear regret,
  while EVILL remains performant. Like PHE, EVILL can be implemented in just a few
  lines of code.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: janz24a
month: 0
tex_title: Exploration via linearly perturbed loss minimisation
firstpage: 721
lastpage: 729
page: 721-729
order: 721
cycles: false
bibtex_author: Janz, David and Liu, Shuai and Ayoub, Alex and Szepesv\'{a}ri, Csaba
author:
- given: David
  family: Janz
- given: Shuai
  family: Liu
- given: Alex
  family: Ayoub
- given: Csaba
  family: Szepesv√°ri
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/janz24a/janz24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
