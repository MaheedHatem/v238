---
title: Parameter-Agnostic Optimization under Relaxed Smoothness
software: https://github.com/fhueb/parameter-agnostic-lzlo
abstract: Tuning hyperparameters, such as the stepsize, presents a major challenge
  of training machine learning models. To address this challenge, numerous adaptive
  optimization algorithms have been developed that achieve near-optimal complexities,
  even when stepsizes are independent of problem-specific parameters, provided that
  the loss function is $L$-smooth. However, as the assumption is relaxed to the more
  realistic $(L_0, L_1)$-smoothness, all existing convergence results still necessitate
  tuning of the stepsize. In this study, we demonstrate that Normalized Stochastic
  Gradient Descent with Momentum (NSGD-M) can achieve a (nearly) rate-optimal complexity
  without prior knowledge of any problem parameter, though this comes at the cost
  of introducing an exponential term dependent on $L_1$ in the complexity. We further
  establish that this exponential term is inevitable to such schemes by introducing
  a theoretical framework of lower bounds tailored explicitly for parameter-agnostic
  algorithms. Interestingly, in deterministic settings, the exponential factor can
  be neutralized by employing Gradient Descent with a Backtracking Line Search. To
  the best of our knowledge, these findings represent the first parameter-agnostic
  convergence results under the generalized smoothness condition. Our empirical experiments
  further confirm our theoretical insights.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hubler24a
month: 0
tex_title: Parameter-Agnostic Optimization under Relaxed Smoothness
firstpage: 4861
lastpage: 4869
page: 4861-4869
order: 4861
cycles: false
bibtex_author: H\"{u}bler, Florian and Yang, Junchi and Li, Xiang and He, Niao
author:
- given: Florian
  family: HÃ¼bler
- given: Junchi
  family: Yang
- given: Xiang
  family: Li
- given: Niao
  family: He
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/hubler24a/hubler24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
