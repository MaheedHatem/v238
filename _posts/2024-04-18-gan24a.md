---
title: Contextual Bandits with Budgeted Information Reveal
abstract: Contextual bandit algorithms are commonly used in digital health to recommend
  personalized treatments. However, to ensure the effectiveness of the treatments,
  patients are often requested to take actions that have no immediate benefit to them,
  which we refer to as pro-treatment actions. In practice, clinicians have a limited
  budget to encourage patients to take these actions and collect additional information.
  We introduce a novel optimization and learning algorithm to address this problem.
  This algorithm effectively combines the strengths of two algorithmic approaches
  in a seamless manner, including 1) an online primal-dual algorithm for deciding
  the optimal timing to reach out to patients, and 2) a contextual bandit learning
  algorithm to deliver personalized treatment to the patient. We prove that this algorithm
  admits a sub-linear regret bound. We illustrate the usefulness of this algorithm
  on both synthetic and real-world data.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gan24a
month: 0
tex_title: Contextual Bandits with Budgeted Information Reveal
firstpage: 3970
lastpage: 3978
page: 3970-3978
order: 3970
cycles: false
bibtex_author: Gan, Kyra and Keyvanshokooh, Esmaeil and Liu, Xueqing and Murphy, Susan
author:
- given: Kyra
  family: Gan
- given: Esmaeil
  family: Keyvanshokooh
- given: Xueqing
  family: Liu
- given: Susan
  family: Murphy
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/gan24a/gan24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
