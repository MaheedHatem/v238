---
title: Provable Policy Gradient Methods for Average-Reward Markov Potential Games
software: https://github.com/bluewoods127/AMPG
abstract: We study Markov potential games under the infinite horizon average reward
  criterion. Most previous studies have been for discounted rewards. We prove that
  both algorithms based on independent policy gradient and independent natural policy
  gradient converge globally to a Nash equilibrium for the average reward criterion.
  To set the stage for gradient-based methods, we first establish that the average
  reward is a smooth function of policies and provide sensitivity bounds for the differential
  value functions, under certain conditions on ergodicity and the second largest eigenvalue
  of the underlying Markov decision process (MDP). We prove that three algorithms,
  policy gradient, proximal-Q, and natural policy gradient (NPG), converge to an $\epsilon$-Nash
  equilibrium with time complexity $O(\frac{1}{\epsilon^2})$, given a gradient/differential
  Q function oracle. When policy gradients have to be estimated, we propose an algorithm
  with $\tilde{O}(\frac{1}{\min_{s,a}\pi(a|s)\delta})$ sample complexity to achieve
  $\delta$ approximation error w.r.tÂ the $\ell_2$ norm. Equipped with the estimator,
  we derive the first sample complexity analysis for a policy gradient ascent algorithm,
  featuring a sample complexity of $\tilde{O}(1/\epsilon^5)$. Simulation studies are
  presented.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cheng24a
month: 0
tex_title: Provable Policy Gradient Methods for Average-Reward {M}arkov Potential
  Games
firstpage: 4699
lastpage: 4707
page: 4699-4707
order: 4699
cycles: false
bibtex_author: Cheng, Min and Zhou, Ruida and R. Kumar, P. and Tian, Chao
author:
- given: Min
  family: Cheng
- given: Ruida
  family: Zhou
- given: P.
  family: R. Kumar
- given: Chao
  family: Tian
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/cheng24a/cheng24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
