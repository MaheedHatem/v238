---
title: Leveraging PAC-Bayes Theory and Gibbs Distributions for Generalization Bounds
  with Complexity Measures
software: https://github.com/paulviallard/AISTATS24-Complexity-Measures
abstract: 'In statistical learning theory, a generalization bound usually involves
  a complexity measure imposed by the considered theoretical framework. This limits
  the scope of such bounds, as other forms of capacity measures or regularizations
  are used in algorithms. In this paper, we leverage the framework of disintegrated
  PAC-Bayes bounds to derive a general generalization bound instantiable with arbitrary
  complexity measures. One trick to prove such a result involves considering a commonly
  used family of distributions: the Gibbs distributions. Our bound stands in probability
  jointly over the hypothesis and the learning sample, which allows the complexity
  to be adapted to the generalization gap as it can be customized to fit both the
  hypothesis class and the task.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: viallard24a
month: 0
tex_title: Leveraging {PAC}-{B}ayes Theory and {G}ibbs Distributions for Generalization
  Bounds with Complexity Measures
firstpage: 3007
lastpage: 3015
page: 3007-3015
order: 3007
cycles: false
bibtex_author: Viallard, Paul and Emonet, R\'{e}mi and Habrard, Amaury and Morvant,
  Emilie and Zantedeschi, Valentina
author:
- given: Paul
  family: Viallard
- given: RÃ©mi
  family: Emonet
- given: Amaury
  family: Habrard
- given: Emilie
  family: Morvant
- given: Valentina
  family: Zantedeschi
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/viallard24a/viallard24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
